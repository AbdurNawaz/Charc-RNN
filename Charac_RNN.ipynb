{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Charac-RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdurNawaz/Charc-RNN/blob/master/Charac_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Heby-MvkeAB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from collections import namedtuple\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3UJKHrbeBQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('anna.txt') as f:\n",
        "    text = f.read()\n",
        "vocab = sorted(set(text))\n",
        "vocab_to_int = {c: i for i, c in enumerate(vocab)}\n",
        "int_to_vocab = dict(enumerate(vocab))\n",
        "encoded = np.array([vocab_to_int[c] for c in text], dtype=np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UAlKq8OeSd-",
        "colab_type": "code",
        "outputId": "ecc90bb0-e877-455a-f117-9ea8b07f6353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "text[:100]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6sVGPNBeVfK",
        "colab_type": "code",
        "outputId": "e15c94bc-51e2-4528-8973-506c39c2d72c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "encoded[:100]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([31, 64, 57, 72, 76, 61, 74,  1, 16,  0,  0,  0, 36, 57, 72, 72, 81,\n",
              "        1, 62, 57, 69, 65, 68, 65, 61, 75,  1, 57, 74, 61,  1, 57, 68, 68,\n",
              "        1, 57, 68, 65, 67, 61, 26,  1, 61, 78, 61, 74, 81,  1, 77, 70, 64,\n",
              "       57, 72, 72, 81,  1, 62, 57, 69, 65, 68, 81,  1, 65, 75,  1, 77, 70,\n",
              "       64, 57, 72, 72, 81,  1, 65, 70,  1, 65, 76, 75,  1, 71, 79, 70,  0,\n",
              "       79, 57, 81, 13,  0,  0, 33, 78, 61, 74, 81, 76, 64, 65, 70],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmDRe1xgeXp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(arr, batch_size, n_steps):\n",
        "  char_per_batch = batch_size*n_steps\n",
        "  num_batches = len(arr)//char_per_batch\n",
        "\n",
        "  arr = arr[:num_batches*char_per_batch]\n",
        "  arr = arr.reshape((batch_size, -1))\n",
        "\n",
        "  for i in range(0, arr.shape[1], n_steps):\n",
        "    x = arr[:, i:i+n_steps]\n",
        "    y_temp = arr[:, i+1:i+n_steps+1]\n",
        "\n",
        "    y = np.zeros(x.shape, dtype=x.dtype)\n",
        "    y[:, :y_temp.shape[1]] = y_temp\n",
        "\n",
        "    yield x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pVGb8iKz5LS",
        "colab_type": "code",
        "outputId": "ed16d0a0-fa3c-4024-a302-9cc44f61cbac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "batches = get_batches(encoded, 10, 50)\n",
        "x, y = next(batches)\n",
        "print('x\\n', x[:, :10])\n",
        "print('y\\n', y[:, :10])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x\n",
            " [[31 64 57 72 76 61 74  1 16  0]\n",
            " [ 1 57 69  1 70 71 76  1 63 71]\n",
            " [78 65 70 13  0  0  3 53 61 75]\n",
            " [70  1 60 77 74 65 70 63  1 64]\n",
            " [ 1 65 76  1 65 75 11  1 75 65]\n",
            " [ 1 37 76  1 79 57 75  0 71 70]\n",
            " [64 61 70  1 59 71 69 61  1 62]\n",
            " [26  1 58 77 76  1 70 71 79  1]\n",
            " [76  1 65 75 70  7 76 13  1 48]\n",
            " [ 1 75 57 65 60  1 76 71  1 64]]\n",
            "y\n",
            " [[64 57 72 76 61 74  1 16  0  0]\n",
            " [57 69  1 70 71 76  1 63 71 65]\n",
            " [65 70 13  0  0  3 53 61 75 11]\n",
            " [ 1 60 77 74 65 70 63  1 64 65]\n",
            " [65 76  1 65 75 11  1 75 65 74]\n",
            " [37 76  1 79 57 75  0 71 70 68]\n",
            " [61 70  1 59 71 69 61  1 62 71]\n",
            " [ 1 58 77 76  1 70 71 79  1 75]\n",
            " [ 1 65 75 70  7 76 13  1 48 64]\n",
            " [75 57 65 60  1 76 71  1 64 61]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scZKGbSb0IQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_inputs(batch_size, n_steps):\n",
        "  inputs = tf.placeholder(tf.int32, [batch_size, n_steps], 'inputs')\n",
        "  targets = tf.placeholder(tf.int32, [batch_size, n_steps], 'targets')\n",
        "\n",
        "  keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
        "\n",
        "  return inputs, targets, keep_prob\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl-oELmH3vbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_lstm(lstm_size, num_layers, batch_size, keep_prob):\n",
        "\n",
        "  def build_cell(lstm_size, keep_prob):\n",
        "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
        "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
        "\n",
        "    return drop\n",
        "  \n",
        "  cell = tf.contrib.rnn.MultiRNNCell([build_cell(lstm_size, keep_prob) for _ in range(num_layers)])\n",
        "  initial_state = cell.zero_state(batch_size, tf.float32)\n",
        "\n",
        "  return cell, inital_state\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhWDgjqe9B0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_output(lstm_output, in_size, out_size):\n",
        "  seq_output = tf.concat(lstm_output, axis=1)\n",
        "  x = tf.reshape(seq_output, [-1, in_size])\n",
        "\n",
        "  with tf.variable_scope('softmax'):\n",
        "    softmax_w = tf.Variable(tf.truncated_normal((insize, out_size), stddev=0.1))\n",
        "    softmax_b = tf.Variable(tf.zeros(out_size))\n",
        "\n",
        "  logits = tf.matmul(x, softmax_w) + softmax_b\n",
        "\n",
        "  out = tf.nn.softmax(logits, name='predictions')\n",
        "\n",
        "  return out, logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zZw15w-DlTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_loss(logits, targets, lstm_size, num_classes):\n",
        "\n",
        "  y_one_hot = tf.one_hot(targets, num_classes)\n",
        "  y_reshaped = tf.reshaped(y_one_hot, logits.shape)\n",
        "\n",
        "  loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_reshaped)\n",
        "  loss = tf.reduce_mean(loss)\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD7y7CcyFf0q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Clipping Gradients to avoid exploding\n",
        "\n",
        "def build_optimizer(loss, learning_rate, grad_clip):\n",
        "  tvars = tf.trainalbe_variables()\n",
        "  grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
        "  train_op = tf.train.AdamOptimizer(leaning_rate)\n",
        "  optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
        "\n",
        "  return optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ6STtrMGn5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class charRNN:\n",
        "\n",
        "  def __init__(self, num_classes, batch_size=64, num_steps=50, lstm_size=128,\n",
        "               num_layers=2, learning_rate=0.001, grad_clip=5, sampling=False):\n",
        "    if sampling == True:\n",
        "      batch_szie, num_steps = 1, 1\n",
        "    else:\n",
        "      batch_size, num_steps = batch_size, num_steps\n",
        "\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    self.inputs, self.targets, self.keep_prob = build_inputs(batch_size, num_steps)\n",
        "    cell, self.initial_state = build_lstm(lstm_size, num_layers, batch_size, self.keep_prob)\n",
        "\n",
        "    x_one_hot = tf.one_hot(self.inputs, num_classes)\n",
        "\n",
        "    outputs, state = tf.nn.dynamic_rnn(cell, x_one_hot, initial_state=self.initial_state)\n",
        "    self.final_state = state \n",
        "    self.predication, self.logits = build_output(outputs,lstm_size, num_classes)\n",
        "\n",
        "    self.loss = build_loss(self.logits, self.targets, lstm_size, num_classes)\n",
        "    self.optimizer = build_optimizer(self.loss, learning_rate, grad_clip)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtowiabZJfsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}